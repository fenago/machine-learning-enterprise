{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam dataset with ensemble methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import utils\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The spam email dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = np.array([\n",
    "    [7,8,1],\n",
    "    [3,2,0],\n",
    "    [8,4,1],\n",
    "    [2,6,0],\n",
    "    [6,5,1],\n",
    "    [9,6,1],\n",
    "    [8,5,0],\n",
    "    [7,1,0],\n",
    "    [1,9,1],\n",
    "    [4,7,0],\n",
    "    [1,3,0],\n",
    "    [3,10,1],\n",
    "    [2,2,1],\n",
    "    [9,3,0],\n",
    "    [5,3,0],\n",
    "    [10,1,0],\n",
    "    [5,9,1],\n",
    "    [10,8,1],\n",
    "])\n",
    "spam_dataset = pd.DataFrame(data=emails, columns=[\"Lottery\", \"Sale\", \"Spam\"])\n",
    "spam_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = spam_dataset[['Lottery', 'Sale']]\n",
    "labels = spam_dataset['Spam']\n",
    "utils.plot_points(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_classifier = DecisionTreeClassifier(random_state=0)\n",
    "decision_tree_classifier.fit(features, labels)\n",
    "decision_tree_classifier.score(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.display_tree(decision_tree_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_model(features, labels, decision_tree_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a random forest by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = spam_dataset.loc[[0,1,2,3,4,5]]\n",
    "features1 = first_batch[['Lottery', 'Sale']]\n",
    "labels1 = first_batch['Spam']\n",
    "utils.plot_points(features1, labels1)\n",
    "plt.show()\n",
    "\n",
    "second_batch = spam_dataset.loc[[6,7,8,9,10,11]]\n",
    "features2 = second_batch[['Lottery', 'Sale']]\n",
    "labels2 = second_batch['Spam']\n",
    "utils.plot_points(features2, labels2)\n",
    "plt.show()\n",
    "\n",
    "third_batch = spam_dataset.loc[[12,13,14,15,16,17]]\n",
    "features3 = third_batch[['Lottery', 'Sale']]\n",
    "labels3 = third_batch['Spam']\n",
    "utils.plot_points(features3, labels3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1 = DecisionTreeClassifier(random_state=0, max_depth=1)\n",
    "dt1.fit(features1, labels1)\n",
    "print(\"Weak learner 1 training accuracy:\", dt1.score(features1, labels1))\n",
    "tree.plot_tree(dt1, rounded=True)\n",
    "plt.show()\n",
    "utils.plot_model(features1, labels1, dt1)\n",
    "\n",
    "dt2 = DecisionTreeClassifier(random_state=0, max_depth=1)\n",
    "dt2.fit(features2, labels2)\n",
    "print(\"Weak learner 2 training accuracy:\", dt2.score(features2, labels2))\n",
    "tree.plot_tree(dt2, rounded=True)\n",
    "plt.show()\n",
    "utils.plot_model(features2, labels2, dt2)\n",
    "\n",
    "dt3 = DecisionTreeClassifier(random_state=0, max_depth=1)\n",
    "dt3.fit(features3, labels3)\n",
    "print(\"Weak learner 3 training accuracy:\", dt3.score(features3, labels3))\n",
    "tree.plot_tree(dt3, rounded=True)\n",
    "plt.show()\n",
    "utils.plot_model(features3, labels3, dt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.display_tree(dt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.display_tree(dt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.display_tree(dt3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a random forest using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest_classifier = RandomForestClassifier(random_state=0, n_estimators=5, max_depth=1)\n",
    "random_forest_classifier.fit(features, labels)\n",
    "random_forest_classifier.score(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_model(features, labels, random_forest_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dt in random_forest_classifier.estimators_:\n",
    "    print(\"*\"*30, \"Estimator\", \"*\"*30)\n",
    "    tree.plot_tree(dt, rounded=True)\n",
    "    plt.show()\n",
    "    utils.plot_model(features, labels, dt)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# Set the random_state so that we always get the same results\n",
    "adaboost_classifier = AdaBoostClassifier(random_state=0, n_estimators=6)\n",
    "adaboost_classifier.fit(features, labels)\n",
    "adaboost_classifier.score(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_model(features, labels, adaboost_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = adaboost_classifier.estimators_\n",
    "for estimator in estimators:\n",
    "    utils.plot_model(features, labels, estimator)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_classifier.estimator_weights_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gradient_boosting_classifier = GradientBoostingClassifier(random_state=0, n_estimators=5)\n",
    "gradient_boosting_classifier.fit(features, labels)\n",
    "gradient_boosting_classifier.score(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_model(features, labels, gradient_boosting_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = gradient_boosting_classifier.estimators_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let us plot the first of the estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.display_tree(estimators[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "xgboost_classifier = XGBClassifier(random_state=0, n_estimators=5)\n",
    "xgboost_classifier.fit(np.array(features), labels)\n",
    "xgboost_classifier.score(np.array(features), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_model(features, labels, xgboost_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
